# 色彩/位深

可能有许多人会问：为什么

## YUV与RGB

我们的显示器使用的一般都是RGB色彩模型，RGB三个色彩屏幕都属于强度，而视频所使用的YUV则不然。

YUV其实就是将RGB经过一定的转换后得到的的另一种表示方式，具体如何转换我们在这里暂且不说，有兴趣的可以在[这里](https://en.wikipedia.org/wiki/YUV)了解一下。

YUV模型有很多具体的实现方式，而日常我们接触最多的就是YCbCr模型。它把RGB转换成一个亮度（Y）和两个色度（CbCr）。

![Y&#x5E73;&#x9762;](https://i.v2ex.co/Pp8ZCS0r.png)

![&#x53EA;&#x6709;Cb&#x8272;&#x5EA6;](https://i.v2ex.co/wXyXf104.png)

![&#x53EA;&#x6709;Cr&#x8272;&#x5EA6;](https://i.v2ex.co/5x23TI82.png)

由于人类对亮度的敏感程度远高于色度，因此我们能看到的有效信息大部分来源于亮度（也就是Y）平面，而正因为YUV模型把大部分有效信息都集中在了Y平面，所以我们可以牺牲色度平面不必要的信息来大大的节省传输过程中所占的信息量，这就引出了色度采样的概念。

## 色度采样（Chroma subsampling）

嘿，既然人眼对色彩信息不敏感，为什么我们不想办法削减色度平面信息呢！

所以，我们今天接触到的绝大多数视频都是以一种叫做`4:2:0`的方式进行色度半采样的，最简单粗暴的理解就是：色度信息的分辨率是亮度信息的四分之一，也就是如果一个`YUV`，以`4:2:0`进行色度抽样的视频的分辨率是`1920x1080`，那它的色度分辨率就只有`960x540`。如果你想对此有更深入的了解，可以从[维基百科的色度采样词条](https://zh.wikipedia.org/wiki/%E8%89%B2%E5%BA%A6%E6%8A%BD%E6%A0%B7)了解它。

![&#x56FE;&#x81EA;&#x7EF4;&#x57FA;&#x767E;&#x79D1;-&#x8272;&#x5EA6;&#x91C7;&#x6837;&#x8BCD;&#x6761;](https://i.v2ex.co/xJ7C55a0.png)

通过将色度信息分辨率减半，我们就能获得观感差不了多少的YUV色彩模型的视频了。在播放过程中，播放器需要将色度平面通过算法拉伸到和亮度平面一样的分辨率，再转为RGB喂给显示器输出，如果你使用的是madvr，随便打开一个420采样的视频并且保持原本分辨率播放，可以不难发现madvr仅对色度平面进行了缩放，这样的缩放算法好坏其实也影响了最后回放时的观感。

![madvr&#x5229;&#x7528;NGU&#x62C9;&#x4F38;&#x8272;&#x5EA6;&#x5E73;&#x9762;&#xFF0C;&#x800C;&#x6CA1;&#x6709;&#x5BF9;&#x4EAE;&#x5EA6;&#x5E73;&#x9762;&#x8FDB;&#x884C;&#x5904;&#x7406;](https://i.v2ex.co/ugiGK0BN.png)

## 位深（BitDepth）



